{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, date\n",
    "import os\n",
    "import os, glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define drought extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drough_extract(id, th_type, moving_window, thresh_value, min_dur, path_id, path_out):\n",
    "# (th_type = threshold type, that can be fixed or variable; moving_window in number of days; thresh_value in flow percentile; min_dur in days)\n",
    "# the streamflow values should be in mm/day    \n",
    "\n",
    "    moving_window=moving_window\n",
    "    thresh_value=thresh_value\n",
    "    min_dur=min_dur\n",
    "\n",
    "  ###  load df\n",
    "    df = pd.read_csv(path_id)\n",
    "\n",
    "  ### convert date to posixct format\n",
    "    df['Datetime']=pd.to_datetime(df['Datetime'], format=\"%Y-%m-%d\")\n",
    "\n",
    "  ### extract date details\n",
    "    df[\"day\"] = df['Datetime'].map(lambda x: x.day)\n",
    "    df[\"month\"] = df['Datetime'].map(lambda x: x.month)\n",
    "    df[\"year\"] = df['Datetime'].map(lambda x: x.year)\n",
    "\n",
    "  ### remove 29.02\n",
    "    drop=list(df[(df['day'] ==29) & (df['month'] ==2)].index)\n",
    "    df=df.drop(drop)\n",
    "    df=df.reset_index(drop=True)\n",
    "\n",
    "  ### Smooth time series\n",
    "    ts=df['streamflow(mm/d)']\n",
    "    \n",
    "    ma_ts=ts.rolling(moving_window, min_periods=1, center=True).mean()\n",
    "\n",
    "  #### fixed threshold\n",
    "    if th_type == 'fixed':\n",
    "        thr = np.nanquantile(df['streamflow(mm/d)'],thresh_value)\n",
    "        thr=np.full(365, thr)\n",
    "      ### in case of a zero threshold, slightly elevate the threshold\n",
    "        if thr[0]==0:\n",
    "            thr=thr.np.full(0.01,365)\n",
    "        else:\n",
    "            thr=np.full(365, thr)\n",
    "    converter= lambda x: x.timetuple().tm_yday\n",
    "    \n",
    " #### variable threshold   \n",
    "    if th_type == 'variable':\n",
    "        if (len(df.year))==len(df ['year'])*365: \n",
    "            df['day_id']==np.tile( np.arange(0,365),(len(df.year.unique())))\n",
    "        else:\n",
    "            df['day_id']=df['Datetime'].map(converter)\n",
    "\n",
    "        thr=[]\n",
    "        \n",
    "        for d in range(0,365):\n",
    "        ### define window length\n",
    "            win_length=np.arange(0,15) \n",
    "            before = list(df.day_id[d+365-win_length])\n",
    "            after = list(df.day_id[d+365+win_length-1])\n",
    "            ### define days within window\n",
    "            ids_win = before+after\n",
    "            ### determine values in window around day i\n",
    "            data_window = ma_ts[df[df['day_id'].isin(ids_win)].index]\n",
    "            quant_value = np.nanquantile(data_window,thresh_value)\n",
    "            thr.append(quant_value)\n",
    "            \n",
    "    ### create column in table with corresponding thresholds\n",
    "    df['threshold']=np.tile(thr,len(df.year.unique()))[:df.shape[0]]\n",
    "\n",
    "    ### idetify events below threshold\n",
    "    deficit_ids=np.where(ma_ts < df['threshold'])[0].tolist()\n",
    "    deficit_datetime=df[df.index.isin(np.where(ma_ts < df['threshold'])[0].tolist())].Datetime\n",
    "    end=np.where(np.array([x - deficit_ids[i - 1] for i, x in enumerate(deficit_ids)][1:]) >1)[0]\n",
    "    start=end+1\n",
    "    start=np.insert(start, 0,0)\n",
    "    end=np.insert(end,len(end),(len(deficit_ids)-1))\n",
    "    start_ids=[deficit_ids[index] for index in start]\n",
    "    end_ids=[deficit_ids[index] for index in end]\n",
    "\n",
    "   ### compute drought characteristics\n",
    "    duration = []\n",
    "    deficit = []\n",
    "    intensity = []\n",
    "    start_date = []\n",
    "    end_date = []\n",
    "    date = []\n",
    "    thresh_events = []\n",
    "    \n",
    "    for e in range(len(start_ids)):\n",
    "        duration.append(end[e] - start[e])\n",
    "        deficit.append(abs(sum(ma_ts[start_ids[e]:(end_ids[e]+1)]-df.threshold[start_ids[e]:(end_ids[e]+1)])))\n",
    "        intensity.append(min(ma_ts[start_ids[e]:(end_ids[e]+1)]))\n",
    "        start_date.append(df.Datetime[start_ids[e]])\n",
    "        end_date.append(df.Datetime[end_ids[e]])\n",
    "        date.append(df[start_ids[e]:(end_ids[e]+1)].loc[ma_ts[start_ids[e]:(end_ids[e]+1)].idxmin()].Datetime)\n",
    "        thresh_events.append(df[start_ids[e]:(end_ids[e]+1)].loc[ma_ts[start_ids[e]:(end_ids[e]+1)].idxmin()].threshold)\n",
    "\n",
    "    event_df=pd.DataFrame(\n",
    "        {'start_date':start_date,\n",
    "        'end_date':end_date,\n",
    "        'date':date,\n",
    "        'thresh_events':thresh_events,\n",
    "         'duration': duration, #days\n",
    "        'deficit': deficit, #mm\n",
    "        'intensity': intensity, #mm/day\n",
    "        })\n",
    "  ### remove events shorter than the minimum duration\n",
    "    if len(np.where(event_df.duration<min_dur)[0].tolist()) >0:\n",
    "        event_df=event_df.drop(np.where(event_df.duration<min_dur)[0].tolist(),axis=0) \n",
    "        \n",
    "  ### save files\n",
    "    path_to_save=os.path.join(path_out,\"Cabra_\"+str(id)+'_th'+str(thresh_value)+'_mw'+str(moving_window)+'_md'+str(min_dur))\n",
    "    event_df.to_csv(path_to_save+\".csv\", sep=',',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##Load data\n",
    "path_id = os.listdir('C:/Users/User/Downloads/Cabra/Data/database_mm/')\n",
    "path_out= 'C:/Users/User/Downloads/Cabra/Drought/Q20_20mw'\n",
    "path_att = pd.read_csv(f'C:/Users/User/Downloads/Cabra/CABra_attibutes_att.csv', sep=',', index_col= 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
     ]
    }
   ],
   "source": [
    "for i in path_id:\n",
    "    id=int(i.split(\"_\")[1])\n",
    "    path=os.path.join('C:/Users/User/Downloads/Cabra/Data/database_mm/',i)\n",
    "    zeros= path_att.loc[{id},'% of zeros']\n",
    "    if float(zeros)<=0.05:\n",
    "        drough_extract(id, 'variable', 20, 0.20, 30, path, path_out)\n",
    "        print(\"successfully done:\",i)\n",
    "    else:\n",
    "        print(i, \"is ephemeral\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_env",
   "language": "python",
   "name": "geopandas_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
